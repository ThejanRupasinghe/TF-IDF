{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_number_string = '140000X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_number = int(index_number_string[4:6])\n",
    "index_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    print(fname)\n",
    "    with open(os.path.join(path, fname)) as doc:\n",
    "        text = doc.read()\n",
    "        return text.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document1.txt\n",
      "document2.txt\n",
      "document3.txt\n"
     ]
    }
   ],
   "source": [
    "docs = {os.path.splitext(fname)[0]: read_file(fname) for fname in list(os.walk(path))[0][2]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document): \n",
    "    return document.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_raw(documents): \n",
    "    table = {}\n",
    "    for doc in documents: \n",
    "        tf = {}\n",
    "        for word in tokenize(documents[doc]): \n",
    "            if word in tf: \n",
    "                tf[word] += 1\n",
    "            else: \n",
    "                tf[word] = 1\n",
    "        table[doc] = tf\n",
    "    return pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_raw_ = tf_raw(docs)\n",
    "# tf_raw_.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:2401', 'document2:2287', 'document3:2322']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1 = list(map(lambda l, r: l + \":\" + str(r), list(tf_raw_.count().index), list(tf_raw_.count().values)))\n",
    "ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_norm(n):\n",
    "#     return math.log10(1+n)\n",
    "def log_norm(n):\n",
    "    if n <= 0: \n",
    "        return 0\n",
    "    else:\n",
    "        return 1 + math.log10(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_log_norm_ = tf_raw_.applymap(log_norm)\n",
    "# tf_log_norm_.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:abide,1.0',\n",
       " 'document2:abandon,1.0',\n",
       " 'document3:aapd,1.6020599913279625']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2 = [\n",
    "    col + \":\" + \n",
    "    tf_log_norm_[col].dropna().index[index_number] + \",\" +\n",
    "    str(tf_log_norm_[col].dropna()[index_number]) \n",
    "    for col in tf_log_norm_.columns.values\n",
    "]\n",
    "ans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_func(n, nt):\n",
    "    return math.log10(n/nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_ = tf_raw_.apply(lambda a: idf_func(len(a), a.count()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:abide,0.47712125471966244',\n",
       " 'document2:abandon,0.47712125471966244',\n",
       " 'document3:aapd,0.47712125471966244']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans3 = [\n",
    "    col + \":\" + \n",
    "    tf_log_norm_[col].dropna().index[index_number] + \",\" +\n",
    "    str(idf_[index_number]) \n",
    "    for col in tf_log_norm_.columns.values\n",
    "]\n",
    "ans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_ = tf_log_norm_.fillna(0).rmul(idf_, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TFIDF = (1 + \\log f_{t,d})\\times \\log\\frac{N}{n_t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:corruption,contribution,candidates,political,candidate,election,ban,buckley,closely,corporate',\n",
       " 'document2:ctdep,east,pipeline,islander,water,shellfish,benthic,substrate,installation,habitat',\n",
       " 'document3:prostitution,rust,plaintiffs,velazquez,subsidy,message,recipients,guidelines,representation,taxation']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans4 = [\n",
    "    col + \":\" + \n",
    "    \",\".join(tf_idf_[col].nlargest(10).index.values.tolist())\n",
    "    for col in tf_idf_.columns\n",
    "]\n",
    "ans4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\\n\".join([index_number_string, \"1\", *ans1, \"\", \"2\", *ans2, \"\", \"3\", *ans3, \"\", \"4\", *ans4])\n",
    "# answer = \"\\r\\n\".join([index_number_string, \"1\", *ans1, \"\", \"2\", *ans2, \"\", \"3\", *ans3, \"\", \"4\", *ans4])\n",
    "# The sample answer.txt file has Windows line endings. (That won't probably matter.) Safety first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'w+') as outfile:\n",
    "    outfile.write(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
