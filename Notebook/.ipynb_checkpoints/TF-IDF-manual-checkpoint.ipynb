{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_number_string = '140004E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_number = int(index_number_string[4:6])\n",
    "index_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    print(fname)\n",
    "    with open(os.path.join(path, fname)) as doc:\n",
    "        text = doc.read()\n",
    "        return text.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document1.txt\n",
      "document2.txt\n",
      "document3.txt\n"
     ]
    }
   ],
   "source": [
    "docs = {os.path.splitext(fname)[0]: read_file(fname) for fname in list(os.walk(path))[0][2]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document): \n",
    "    return document.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_raw(documents): \n",
    "    table = {}\n",
    "    for doc in documents: \n",
    "        tf = {}\n",
    "        for word in tokenize(documents[doc]): \n",
    "            if word in tf: \n",
    "                tf[word] += 1\n",
    "            else: \n",
    "                tf[word] = 1\n",
    "        table[doc] = tf\n",
    "    return pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_raw_ = tf_raw(docs)\n",
    "# tf_raw_.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:2401', 'document2:2287', 'document3:2322']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1 = list(map(lambda l, r: l + \":\" + str(r), list(tf_raw_.count().index), list(tf_raw_.count().values)))\n",
    "ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_norm(n):\n",
    "#     return math.log10(1+n)\n",
    "def log_norm(n):\n",
    "    if n <= 0: \n",
    "        return 0\n",
    "    else:\n",
    "        return 1 + math.log10(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_log_norm_ = tf_raw_.applymap(log_norm)\n",
    "# tf_log_norm_.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:accept,1.6020599913279625',\n",
       " 'document2:abundant,1.3010299956639813',\n",
       " 'document3:absent,1.4771212547196624']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2 = [\n",
    "    col + \":\" + \n",
    "    tf_log_norm_[col].dropna().index[index_number] + \",\" +\n",
    "    str(tf_log_norm_[col].dropna()[index_number]) \n",
    "    for col in tf_log_norm_.columns.values\n",
    "]\n",
    "ans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_func(n, nt):\n",
    "    return math.log10(n/nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_ = tf_raw_.apply(lambda a: idf_func(len(a), a.count()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aapd          0.477121\n",
       "abandon       0.477121\n",
       "abdicate      0.477121\n",
       "abide         0.176091\n",
       "ability       0.000000\n",
       "able          0.000000\n",
       "abolition     0.477121\n",
       "abortion      0.477121\n",
       "about         0.000000\n",
       "above         0.000000\n",
       "abramoff      0.477121\n",
       "abrams        0.477121\n",
       "abridging     0.477121\n",
       "abridgment    0.477121\n",
       "abrogate      0.477121\n",
       "absence       0.176091\n",
       "absent        0.176091\n",
       "absolutely    0.477121\n",
       "abstinence    0.477121\n",
       "absurd        0.477121\n",
       "abundance     0.477121\n",
       "abundant      0.477121\n",
       "abuse         0.176091\n",
       "abuses        0.477121\n",
       "academic      0.477121\n",
       "accept        0.000000\n",
       "acceptable    0.000000\n",
       "acceptance    0.176091\n",
       "accepted      0.477121\n",
       "accepting     0.176091\n",
       "                ...   \n",
       "worded        0.477121\n",
       "words         0.176091\n",
       "work          0.000000\n",
       "workers       0.477121\n",
       "working       0.477121\n",
       "works         0.176091\n",
       "world         0.477121\n",
       "worldcom      0.477121\n",
       "worms         0.477121\n",
       "worth         0.477121\n",
       "would         0.000000\n",
       "wqc           0.477121\n",
       "wqcs          0.477121\n",
       "write         0.477121\n",
       "writing       0.176091\n",
       "wrong         0.477121\n",
       "wrought       0.477121\n",
       "xpression     0.477121\n",
       "yards         0.477121\n",
       "year          0.000000\n",
       "years         0.000000\n",
       "yet           0.000000\n",
       "york          0.000000\n",
       "yorkers       0.477121\n",
       "you           0.477121\n",
       "young         0.477121\n",
       "your          0.477121\n",
       "zajac         0.477121\n",
       "zone          0.477121\n",
       "zoning        0.477121\n",
       "Length: 4745, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:accept,0.0',\n",
       " 'document2:abundant,0.47712125471966244',\n",
       " 'document3:absent,0.17609125905568124']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans3 = [\n",
    "    col + \":\" + \n",
    "    tf_log_norm_[col].dropna().index[index_number] + \",\" +\n",
    "    str(idf_[tf_log_norm_[col].dropna().index[index_number]]) \n",
    "    for col in tf_log_norm_.columns.values\n",
    "]\n",
    "ans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_ = tf_log_norm_.fillna(0).rmul(idf_, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TFIDF = (1 + \\log f_{t,d})\\times \\log\\frac{N}{n_t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document1:corruption,contribution,candidates,political,candidate,election,ban,buckley,closely,corporate',\n",
       " 'document2:ctdep,east,pipeline,islander,water,shellfish,benthic,substrate,installation,habitat',\n",
       " 'document3:prostitution,rust,plaintiffs,velazquez,subsidy,message,recipients,guidelines,representation,taxation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans4 = [\n",
    "    col + \":\" + \n",
    "    \",\".join(tf_idf_[col].nlargest(10).index.values.tolist())\n",
    "    for col in tf_idf_.columns\n",
    "]\n",
    "ans4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\\n\".join([index_number_string, \"1\", *ans1, \"\", \"2\", *ans2, \"\", \"3\", *ans3, \"\", \"4\", *ans4])\n",
    "# answer = \"\\r\\n\".join([index_number_string, \"1\", *ans1, \"\", \"2\", *ans2, \"\", \"3\", *ans3, \"\", \"4\", *ans4])\n",
    "# The sample answer.txt file has Windows line endings. (That won't probably matter.) Safety first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'w+') as outfile:\n",
    "    outfile.write(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
